{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitvenvvenvad14fe486b5c45149d0945bca7d34922",
   "display_name": "Python 3.6.8 64-bit ('venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NID Validation Checks\n",
    "\n",
    "Perform a check of the integrity of NID values within the dataset. This is done to make sure that all of the NID values within the dataset adhere to the rules as defined in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# used for reading shapefiles - not required for GPKG data\n",
    "from simpledbf import Dbf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRPLANAME Checks\n",
    "\n",
    "Using the STRPLANAME dbf data, check for any mismatches in NID vs segment idenfitication fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset and the layer name for multilayered data.\n",
    "data_path = Path('../../nrn_data/NRN_RRN_PE_18_0_GPKG/NRN_PE_18_0_GPKG/NRN_PE_18_0.gpkg')\n",
    "data_layer = 'NRN_PE_18_0_STRPLANAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path('../../nrn_data/nrn_rrn_nb_shp_en/NRN_NB_8_0_STRPLANAME.dbf')\n",
    "\n",
    "data_path = Path('../../nrn_data/nrn_rrn_ab_shp_en/NRN_AB_14_0_STRPLANAME.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields of interest for comparisons.\n",
    "\n",
    "# The NID field should end up having the same value for every record when the connected segment fields are grouped.\n",
    "nid_field = 'nid'\n",
    "\n",
    "# These fields are grouped together to identify which segments should be idenfied as having a common NID value.\n",
    "connected_segment_fields = ['namebody', 'strtypre', 'strtysuf', 'dirprefix', 'dirsuffix']\n",
    "\n",
    "# The fields we are initerested in analyzing are the combination of the connected segment fields and the NID field.\n",
    "fields_of_concern = connected_segment_fields + [nid_field]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the DBF file into a DataFrame\n",
    "\n",
    "This reads the data from the appropriate source. Both DBF and GPKG sources are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles\n",
    "dbf = Dbf5(data_path)\n",
    "df = dbf.to_dataframe().rename(columns=str.lower).filter(fields_of_concern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoPackage table\n",
    "df = (pd.read_sql_table(data_layer, f\"sqlite:///{data_path.as_posix()}\", coerce_float=False)\n",
    "    .rename(columns=str.lower)\n",
    "    .filter(fields_of_concern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group items by the connected segment fields, and then look for any differences across the groups.\n",
    "problem_nids = []\n",
    "planame_groups = df.groupby(connected_segment_fields)\n",
    "for group_id, group_records in planame_groups:\n",
    "    # ignore any single record groups\n",
    "    if len(group_records) == 1:\n",
    "        continue\n",
    "\n",
    "    # look for duplicates on the records - everything should be duplicated\n",
    "    if not group_records.duplicated().all():\n",
    "        bad_nids = group_records[nid_field].tolist()\n",
    "        problem_nids.append(bad_nids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 27706 groups\nFound 4129 problem groups\n"
    }
   ],
   "source": [
    "print(f\"Found {len(planame_groups)} groups\")\n",
    "print(f\"Found {len(problem_nids)} problem groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['namebody', 'strtypre', 'strtysuf', 'dirprefix', 'dirsuffix', 'nid']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "fields_of_concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}